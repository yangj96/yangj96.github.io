<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=6.7.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.7.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.7.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="Jingy&#39;s Blog">
<meta property="og:url" content="https://yangj96.github.io/index.html">
<meta property="og:site_name" content="Jingy&#39;s Blog">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jingy&#39;s Blog">






  <link rel="canonical" href="https://yangj96.github.io/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Jingy's Blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jingy's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    
  
  
  
  

  

  <a href="https://github.com/yangj96" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" style="fill: #222; color: #fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a>



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://yangj96.github.io/2019/06/29/fnn/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jing Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jingy's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/29/fnn/" class="post-title-link" itemprop="url">神经网络基础</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-29 17:23:49 / 修改时间：17:34:13" itemprop="dateCreated datePublished" datetime="2019-06-29T17:23:49+08:00">2019-06-29</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/DeepLearning/" itemprop="url" rel="index"><span itemprop="name">DeepLearning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">9.5k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">9 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>本文是深度学习总结系列的第一篇，主要内容是神经网络的基础知识。系列更多文章传送门：第二篇 <a href="https://www.jianshu.com/p/71e58c682513" target="_blank" rel="noopener">[Deep Learning] 卷积神经网络 CNNs</a>；第三篇 <a href="https://www.jianshu.com/p/5a26ec734982" target="_blank" rel="noopener">[Deep Learning] 集成学习Ensemble Learning&amp;迁移学习Transfer Learning </a>；第四篇 [ [Deep Learning] 递归神经网络RNN ]（<a href="https://www.jianshu.com/p/5c22b41e9f07" target="_blank" rel="noopener">https://www.jianshu.com/p/5c22b41e9f07</a>。</p>
</blockquote>
<p>本文对人工神经网络（Artificial Neural Networks）的基础内容进行介绍，主要内容包括：</p>
<ol>
<li>神经网络发展史<br>1.1 感知器<br>1.2 反向传播和梯度下降</li>
<li>激活函数</li>
<li>常用参数</li>
<li>优化方法</li>
<li>正则化方法</li>
</ol>
<hr>
<h5 id="1-神经网络发展史-A-Bit-of-History"><a href="#1-神经网络发展史-A-Bit-of-History" class="headerlink" title="1.  神经网络发展史 A Bit of History"></a>1.  神经网络发展史 <a href="https://upc-mai-dl.github.io/mlp-convnets-theory/#history" target="_blank" rel="noopener">A Bit of History</a></h5><p>人工神经网络领域的第一篇论文诞生于1943年，由Warren McCulloch和Walter Pitts发表[^1]。在这篇论文中两人试图解释大脑是如何使用神经元这一简单的处理单元来计算高度复杂的行为，并设计了多输入权重的单个神经元模型来模拟人类神经元。</p>
<h6 id="1-1-感知器-Rosenblatt’s-Perceptron"><a href="#1-1-感知器-Rosenblatt’s-Perceptron" class="headerlink" title="1.1 感知器  Rosenblatt’s Perceptron"></a>1.1 感知器  <a href="https://upc-mai-dl.github.io/mlp-convnets-theory/#rosenblatt" target="_blank" rel="noopener">Rosenblatt’s Perceptron</a></h6><p>1958年，Frank Rosenblatt基于McCulloch和Walter Pitts的神经元理论提出感知器算法[^2]，感知器是一个将实值输入映射为0/1输出的二元分类器。</p>
<ul>
<li>$$f(x)= \begin{cases}1 \; if \; w \cdot x+b&gt;0 \<br>0 otherwise \end{cases}$$<br>（其中，w是权重向量，b是偏移常量）</li>
</ul>
<p>Rosenblatt在 “Mark I Perceptron”[^3]中首次实践采用了感知器算法。“Mark I Perceptron”是一个由400个光敏感受器组成的视觉分类器，与512个步进电机相关联，输出8个神经元[^3]。它仅仅包含一层可训练的参数，关于这一感知器的更多细节可参考[^4][^5]。<br><img src="https://upload-images.jianshu.io/upload_images/2764802-acc361aa37c55123.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Mark I Perceptron"><br>Rosenblatt在一系列出版物中承认他的感知器存在局限性，与此同时，Minsky和Papert出版了“Perceptrons: an introduction to computational geometry”一书，详细介绍了感知器的局限性[^6]。 Minsky和Papert的工作对公众产生了巨大影响，尽管很少有人真正理解他们研究的本质。 简言之，Minsky和Papert认为对于某些基本问题，例如异或问题，单层网络不能满足需求，然而当时并没有适合多层网络进行训练的算法，因此70年代人工神经网络的资金开始大幅减少直至80年代中期，在人工神经网络几乎被放弃之后，人工智能研究的重点开始转向“专家系统”，虽然这些系统在90年代也将遭遇自己的“人工智能寒冬”。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/2764802-2545868355540c91.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="单层神经网络只能解决线性问题"></p>
<h6 id="1-2-反向传播和随机梯度下降-Backpropagation-and-Stochastic-Gradient-Descent"><a href="#1-2-反向传播和随机梯度下降-Backpropagation-and-Stochastic-Gradient-Descent" class="headerlink" title="1.2 反向传播和随机梯度下降 Backpropagation and Stochastic Gradient Descent"></a>1.2 反向传播和随机梯度下降 <a href="https://upc-mai-dl.github.io/mlp-convnets-theory/#backprop" target="_blank" rel="noopener">Backpropagation and Stochastic Gradient Descent</a></h6><p>1974年，Werbos提出了针对多层神经网络训练的反向传播算法[^werbos]。1985年，Rumelhart，<a href="http://www.cs.toronto.edu/~hinton/" target="_blank" rel="noopener">Geoffrey E. Hinton</a>和Williams重新发现该算法[^rumelhart]并使其获得广泛关注，重新引发了人们对于人工神经网络的研究兴趣，“AI寒冬”时期结束。</p>
<p>要训练多层神经网络，首先从输入开始正向传递直至到达网络的最后一层，然后将神经网络预测的输出标签与标定正确的真实数据标签（the ground truth label）进行比较，并使用损失函数计算误差，通过找到损失函数最小化的最佳梯度（尽管是偏导数）更新网络最末端一层的权重。然后，应用链式规则反向传播，通过将前一层本地计算的梯度与向前传递的梯度相乘，得出那些不直接与输出层相连的隐层的输入值使得损失函数最小化的梯度，如下面的计算图所示。当需要手动推导计算反向传播算法时，简单实用的方法是绘制计算图（computing graph）再代入数值。<br><img src="https://upload-images.jianshu.io/upload_images/2764802-a15dfca35c9d45d1.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="反向传播使用的链式规则"></p>
<p>权重根据梯度方向进行优化，具体调整的变化值使用梯度下降计算。<br>目前常用的随机梯度下降（SGD）的“随机”性主要体现在：SGD使用整个数据集的子集（mini-batch SGD）而不是完整的数据集迭代估计优化的最佳方向，因为整个数据集可能非常大，因而是随机的梯度下降并不能保证每一步都是最优方向。除SGD算法外，现在已有更多改进方案可用于计算权重的变化值进行权重优化，我们将在“优化方法”一节中进一步介绍。</p>
<p>对感知器和反向传播算法等神经网络的系统学习有兴趣可进一步阅读其他相关文章资源[^9]，包括反向传播算法的详细数学解释[^10]、以一组数据为例计算反向传播算法各步骤执行结果[^11]以及了解反向传播算法背后实现原理对解决梯度消失、死亡ReLU单元和RNN梯度爆炸等问题的帮助[^12]，关于算法的一步步导数的数学推导解释可参考[^13]，也可学习Stanford <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">CS231n:Convolutional Neural Networks for Visual Recognition</a>课程的相关内容。</p>
<p>伴随着新的训练方法的出现，ANN的研究重新活跃起来。1989年，<a href="http://yann.lecun.com/" target="_blank" rel="noopener">Yann LeCun</a>，现任Facebook人工智能研究院院长，使用美国邮政局提供的数据开发了一个数字识别系统[^LeCun]，首次展示了如何使用人工神经网络解决复杂的实际问题。LeCun的系统包含一层卷积神经元，基于1980年Fukushima提出的用于视觉模式识别的层次神经网络[^Fukushima]，这是目前卷积神经网络的雏形。</p>
<h5 id="2-激活函数-Activation-Functions"><a href="#2-激活函数-Activation-Functions" class="headerlink" title="2. 激活函数   Activation Functions"></a>2. 激活函数   <a href="https://upc-mai-dl.github.io/mlp-convnets-theory/#activations" target="_blank" rel="noopener">Activation Functions</a></h5><p>人工神经网络的每个神经元使用激活函数来确定多个权重输入对应的输出结果。Rosenblatt的感知器使用最简单的二元函数，如果$w \cdot x+b&gt;0$则激活，输出1，否则不激活。如今我们可以选择其他更复杂的非线性激活函数，非线性激活函数使得神经网络能够对非线性模式进行学习。常用的激活函数包括[^sigmoid]：</p>
<ul>
<li>Sigmoid函数: $f(x)=\frac{1}{1+e^{-x}}$</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/2764802-51b990191199b868.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Sigmoid函数"></p>
<ul>
<li>Tanh函数: $f(x)=\frac{2}{1+e^{-2x}}-1$</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/2764802-bf62446eff44e8e8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Tanh函数"></p>
<ul>
<li>修正线性单元/整流线性单元(The Rectified Linear Unit): $f(x)=max(0,x)$</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/2764802-983c5e42b69a3562.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ReLU"><br>目前，ReLU是大多数情况下默认使用的激活函数，它使用固定的斜率避免了梯度消失问题[^vanishGradient]，梯度消失的主要问题是当使用Sigmoid和Tanh这类将大范围的输入挤到[0,1]或[-1,1]小范围输出区间的激活函数时，随着神经网络误差的反向传播，前层的权重变化对输出结果的影响越来越小直至梯度为零终止学习。</p>
<p>划分指数级空间 具有足够的表达能力</p>
<p>然而，ReLU单位在训练期间可能“死亡”。例如，流过ReLU神经元的大梯度可能导致权重的更新使得神经元无法在任何数据上激活。如果发生这种情况，那么流经该单元的梯度将从该点开始永远为零。也就是说，ReLU单元在训练期间不可逆转地死亡，可以从数据流中被淘汰。例如，如果学习率设置得太高，可能会发现多达网络中40％的神经元可能“死亡”。通过适当设置学习率可以解决该问题。关于激活函数可进一步学习Stanford <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">CS231n</a>课程的相关内容[^acFun]。<strong>神经网络的优化的研究思路可从激活函数优化入手，例如针对手机应用ReLU激活函数时对非饱和区进行优化以大幅提升神经网络性能。</strong></p>
<ul>
<li>Leaky ReLU: $f(x)=max(0.1x, x)$<br>Leaky ReLU试图解决dying ReLU问题，当x &lt;0时，函数不是零，而将具有小的负斜率（大约为0.01）。</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/2764802-240e9852b48c41c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Leaky ReLU"></p>
<ul>
<li>Maxout: $f(x)=max(w_1^Tx+b_1, w_2^Tx + b_2)$<br>ReLU和Leaky ReLU都是这一函数的特例，例如ReLU对应w1,b1=0。</li>
</ul>
<h5 id="3-训练参数-Training-Parameters"><a href="#3-训练参数-Training-Parameters" class="headerlink" title="3. 训练参数   Training Parameters"></a>3. 训练参数   <a href="https://upc-mai-dl.github.io/mlp-convnets-theory/#training_params" target="_blank" rel="noopener">Training Parameters</a></h5><p>3.1 训练次数(Epochs)和批次大小(Batch Size)</p>
<ul>
<li><p>Epoch对应训练集的所有图像都训练被一次的阶段，通常，ANN训练需要许多次，因为每个输入实例将网络参数指引向不同方向，并且网络能够在受到其他实例训练影响后对之前训练过的实例再次训练，从同一示例中不止一次地学习。通常，当epoch次数过多，网络最终将过拟合。过拟合可以通过训练集上的损失降低同时测试集上损失开始上升来识别。</p>
</li>
<li><p>批次大小定义了在单次网络前向和反向传播过程中的输入实例的数量，是网络能够“一起看到”的输入数量。批次大小的范围从1到完整数据集大小。较大的批次大小能够更快地训练，但可能会降低精确度[^batchSize]。批次大小太小可以通过损失函数的噪声[^22]来识别，即某一批次的损失与下一批次是否显著不同。当批次大小越小时摆动越明显，当批次大小等于数据集大小时噪声损失函数方差最小（除非学习率太高，在这种情况下网络无法收敛）。<strong>最常用的批次大小为16和32。</strong></p>
</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/2764802-a1a7ea188115709d.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="在CIFAR-10数据集上训练小型网络时，典型损失函数随时间变化的示例"></p>
<p>3.2 学习率</p>
<ul>
<li>学习率定义了每一步权重优化时的调整比例。通常，使用完全导数（学习率为1）会导致过度修正，学习率太大可能使得神经元在定义的高维空间内产生大的“跳跃”，从而无法收敛。学习率太小会使朝着最佳权重调整的步幅太小，训练时间过长[^learnrate]。<strong>较好的选择是从较小的学习速率开始使权重调整走向正确的方向，然后逐渐增大以加快收敛。</strong>在训练期间跟踪的首先是loss，因为它在前向传递期间在各个批次上被评估。绘制不同学习率下loss随时间的变化可以帮助我们更好地了解学习率的选择。</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/2764802-87f6b5b0d28be8b6.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="关于大小学习率的行为对比"><br><img src="https://upload-images.jianshu.io/upload_images/2764802-b6389ed23b116b48.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="描绘不同学习率影响"></p>
<p>3.3  其他参数<br>还有许多其他参数可能会影响学习过程，包括：</p>
<ul>
<li>权重衰减：每次更新后，权重会乘以一个0到1之间的因子。这是一种正则化的式。</li>
<li><p>权重初始化：训练开始前的初始权重和偏差值bias是训练结果的关键。针对ReLU激活函数的神经元，其权重初始化通常使用随机数并使用$sqrt(2.0/n)$来平衡方差[^weightInit]，而bias通常直接初始化为零。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w = np.random.randn(n) * sqrt(<span class="number">2.0</span>/n)</span><br></pre></td></tr></table></figure>
</li>
<li><p>改进优化方法中的其他参数，例如动量</p>
</li>
</ul>
<h5 id="4-优化方法"><a href="#4-优化方法" class="headerlink" title="4. 优化方法"></a>4. 优化方法</h5><ul>
<li><p>一阶方法<br>梯度下降</p>
</li>
<li><p>二阶方法<br>Hessian 矩阵<br>牛顿法<br>共轭牛顿法<br>伪牛顿法</p>
</li>
</ul>
<p>动量：增加动量项能够使得SGD能够跳出局部最小值(local minima)和鞍点(saddle point)，加快在鞍点附近梯度缓慢处的前进。此外，增加动量项还能解决使用SGD时的Poor Conditioning：当损失函数在一个方向上改变很快而在另一方向改变很慢，使用普通SGD会出现在变化敏感方向上的锯齿跳动，这种情况在高维下很常见。动量项将先前权重更新的一小部分添加到当前权重更新中。如果两次更新在同一方向则会加快收敛，而更新在不同方向上时则会平滑方差，从而能够尽快结束这种情况下的曲折前进(Zigzagging)。<br><img src="https://upload-images.jianshu.io/upload_images/2764802-3587411424fdb3df.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Poorly Condition"></p>
<blockquote>
<ol>
<li>普通SGD（Vanilla update）:<br>$x_{t+1}=x_{t}+ learningrate * dx$<br>(梯度为损失函数下降的方向)</li>
<li>动量SGD（Momentum update）:增加速度值（velocity）初始化为0<br>$v_{t+1}=rho<em>v_{t}+dx$<br>(rho表示摩擦friction，通常设为0.9或0.99)<br>$x_{t+1}=x_{t}+learningrate </em> v_{t+1}$</li>
<li>Nesterov动量:<br>$x_{head} = x_t+rho<em>v_{t}$<br>$v_{t+1}=rho</em>v_{t}+dx_{head}$<br>$x_{t+1}=x_{t}+v_{t+1}$<br><img src="https://upload-images.jianshu.io/upload_images/2764802-6934264f43c3bcc5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="动量方法对比"></li>
</ol>
</blockquote>
<p>关于如何优化这些参数的几个技巧，可参考Stanford cs231n超参数优化部分[^22]。</p>
<p>适应性学习方法   <a href="https://upc-mai-dl.github.io/mlp-convnets-theory/#adaptative_methods" target="_blank" rel="noopener">Adaptative Learning Methods</a><br>SGD学习方法对学习率，动量，权量衰减等诸多参数的调参挑战促使了其他自动化调参学习方法的出现。其中，广受欢迎的方法有Adagrad，Adadelta，RMSprop和Adam。关于这些适应性学习方法的详细介绍参见梯度下降的优化[^41]。<br>最早的牛顿法中通过计算Hessian矩阵可以反映坡度的陡缓，但计算量太大，需要使用full batch。</p>
<ul>
<li>Adagrad: 记录所有梯度的平方和，使得能够在较缓的维度上除以一个较小值进行加速而在较陡的维度上除以一个较大值从而减速。但由于梯度的平方和越来越大，步幅会越来越小，可能会停在鞍点处无法出来，因而Adagrad只适用于卷积层的学习。<blockquote>
<p>$     gradSquared += dx<em>dx$<br>$x_{t+1} = x_{t} + learningrate </em> dx / (np.sqrt(gradSquared) + eps)$<br>其中eps防止</p>
</blockquote>
</li>
<li><p>RMSprop: RMSprop在Adagrad基础上进行小幅改动，对梯度的平方和进行衰减，衰减率（decay rate）通常设为0.9或0.99。实现了指数移动平均，类似于lstm的遗忘门。</p>
<blockquote>
<p>$     gradSquared = decayrate<em>gradSquared+(1-decayrate)</em>dx<em>dx$<br>$x_{t+1} = x_{t} + learningrate </em> dx / (np.sqrt(gradSquared) + eps)$</p>
</blockquote>
</li>
<li><p>Adam: Adam结合了上述两种方法和动量项，最为常用。<br><img src="https://upload-images.jianshu.io/upload_images/2764802-68b1d2ce8de769d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Adam算法"></p>
</li>
</ul>
<p><img src="http://upload-images.jianshu.io/upload_images/2764802-095af8d000b40006.gif?imageMogr2/auto-orient/strip" alt="不同算法在鞍点处的行为比较"><br><img src="https://upload-images.jianshu.io/upload_images/2764802-bcf6bb5a5a8862f1.gif?imageMogr2/auto-orient/strip" alt="不同算法在损失平面等高线上随时间的变化情况"></p>
<h5 id="5-正则化方法-Regularization-Methods"><a href="#5-正则化方法-Regularization-Methods" class="headerlink" title="5. 正则化方法   Regularization Methods"></a>5. 正则化方法   <a href="https://upc-mai-dl.github.io/mlp-convnets-theory/#regularization" target="_blank" rel="noopener">Regularization Methods</a></h5><p>网络的学习能力由其权重数量和深度定义。深层架构通常有数百万参数（AlexNet有60M参数，VGG16有138M参数），其中大量参数来自全连接层，因为卷积层通过权重共享能够大大减少它们的数量。一个具有4,096个神经元的全连接层加上输入层的4,096个神经元就将包含16M参数（4,096 x 4,096）。具有如此多参数的模型对任何训练数据集都很容易过拟和，因为它具有很强的记忆它的能力。为避免过拟合问题，用于深度架构的正则化方法被提出，常用的正则化方法包括：</p>
<ul>
<li>L1 / L2正则化：该方法试图通过对每个权重的平方增加惩罚（将$\frac{1}{2} \lambda w^2$项加入到loss函数中）来避免权重尖峰值的影响。</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/2764802-5f352a8a37140e83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="L1/L2正则化"></p>
<ul>
<li>Dropout [^27]：该方法在训练期间以一定的概率设置部分神经元为0，在全连接层上简单有效。<strong>Dropping概率p通常设为0.5</strong>，但dropout会导致输出结果随机，因此在测试时，根据概率计算的平均结果我们需要将激活函数乘以dropping概率进行伸缩作为最终结果，或在训练时的dropout  mask步骤直接除以dropping概率。</li>
<li>批标准化[^39]：该方法对每批次输入的均值和方差进行标准化，通常用在全连接层之后。它既可以作为正则化方法，也可以解决与权重初始化相关的问题，同时也可以加速收敛。</li>
<li>层标准化[^44]：该方法类似于批标准化，但均值和方差是在每层计算的。这对于批标准化不能直接应用的RNN和完全连接层十分有用，但不适用卷积层。它可以比批标准化更快地加速收敛。</li>
<li>Data Augmentation数据增量：对同一张图片进行随机剪切、伸缩旋转、水平变换、改变亮度对比度、透镜畸变等操作后作为输入数据对网络进行训练。</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/2764802-a6e4775903391f65.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="数据大小变换"><br><img src="https://upload-images.jianshu.io/upload_images/2764802-a14f3b7d6a931413.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="数据色彩变换"></p>
<ul>
<li>Dropconnect：将权重矩阵中的某些值随机设为0，丢弃某些连接。</li>
<li>Fractional Max Pooling：采用不同的pooling区域并在测试时固定平均。</li>
<li>Stochastic Depth：在训练深度非常深的网络时随机丢弃某些层，在测试时再恢复全部使用。</li>
</ul>
<p>批标准化和层标准化、Dropout方法以及数据增量本质都是通过在训练阶段增加某些随机性然后在测试时进行估计将随机性平均化从而实现正则化[^24]。</p>
<p>参考文献<br>[^1]: <a href="http://vordenker.de/ggphilosophy/mcculloch_a-logical-calculus.pdf" target="_blank" rel="noopener">McCulloch, Warren S., and Walter Pitts. “A logical calculus of the ideas immanent in nervous activity.” The bulletin of mathematical biophysics 5.4 (1943): 115-133.</a><br>[^2]: <a href="http://www-public.tem-tsp.eu/~gibson/Teaching/Teaching-ReadingMaterial/Rosenblatt58.pdf" target="_blank" rel="noopener">Rosenblatt, Frank. “The perceptron: A probabilistic model for information storage and organization in the brain.” Psychological review 65.6 (1958): 386</a><br>[^3]: <a href="http://www.dtic.mil/dtic/tr/fulltext/u2/236965.pdf" target="_blank" rel="noopener">Mark I Perceptron Operators’ Manual</a><br>[^4]: Kurzweil, Ray. How to create a mind: The secret of human thought revealed. Penguin, 2013.<br>[^5]: <a href="http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/" target="_blank" rel="noopener">http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/</a><br>[^6]: <a href="https://en.wikipedia.org/wiki/Perceptrons_(book" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Perceptrons_(book)</a>)<br>[^werbos]: <a href="https://upc-mai-dl.github.io/mlp-convnets-theory/" target="_blank" rel="noopener">Webos, Paul John. “Beyond regression: New tools for prediction and analysis in the behavioral sciences.” Doctoral Dissertation, Applied Mathematics, Harvard University (1974)</a><br>[^rumelhart]: <a href="http://www.dtic.mil/get-tr-doc/pdf?AD=ADA164453" target="_blank" rel="noopener">Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. Learning internal representations by error propagation. No. ICS-8506. California Univ San Diego La Jolla Inst for Cognitive Science, 1985.</a><br>[^9]: <a href="http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/" target="_blank" rel="noopener">http://www.andreykurenkov.com/writing/a-brief-history-of-neural-nets-and-deep-learning/</a><br>[^10]: <a href="http://neuralnetworksanddeeplearning.com/chap2.html" target="_blank" rel="noopener">http://neuralnetworksanddeeplearning.com/chap2.html</a><br>[^11]: <a href="https://becominghuman.ai/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c" target="_blank" rel="noopener">https://becominghuman.ai/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c</a><br>[^12]: <a href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b" target="_blank" rel="noopener">https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b</a><br>[^13]: <a href="https://medium.com/@erikhallstrm/backpropagation-from-the-beginning-77356edf427d" target="_blank" rel="noopener">https://medium.com/@erikhallstrm/backpropagation-from-the-beginning-77356edf427d</a><br>[^LeCun]: <a href="http://www.ics.uci.edu/~welling/teaching/273ASpring09/lecun-89e.pdf" target="_blank" rel="noopener">LeCun, Yann, et al. “Backpropagation applied to handwritten zip code recognition.” Neural computation 1.4 (1989): 541-551.</a><br>[^Fukushima]: <a href="https://pdfs.semanticscholar.org/c85e/6878f2048d0ec9d7186e3f20592c543635dd.pdf" target="_blank" rel="noopener">Fukushima, Kunihiko. “Neocognitron: A hierarchical neural network capable of visual pattern recognition.” Neural networks 1.2 (1988): 119-130.</a><br>[^sigmoid]: <a href="https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0" target="_blank" rel="noopener">https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0</a><br>[^vanishGradient]: <a href="https://www.quora.com/What-is-the-vanishing-gradient-problem" target="_blank" rel="noopener">https://www.quora.com/What-is-the-vanishing-gradient-problem</a><br>[^acFun]: <a href="http://cs231n.github.io/neural-networks-1/#actfun" target="_blank" rel="noopener">http://cs231n.github.io/neural-networks-1/#actfun</a><br>[^batchSize]: <a href="https://github.com/fchollet/keras/issues/68" target="_blank" rel="noopener">https://github.com/fchollet/keras/issues/68</a><br>[^22]: <a href="http://cs231n.github.io/neural-networks-3/" target="_blank" rel="noopener">http://cs231n.github.io/neural-networks-3/</a><br>[^learnrate]: <a href="https://www.linkedin.com/pulse/gradient-descent-simple-words-parth-jha" target="_blank" rel="noopener">https://www.linkedin.com/pulse/gradient-descent-simple-words-parth-jha</a><br>[^41]: <a href="http://ruder.io/optimizing-gradient-descent/" target="_blank" rel="noopener">http://ruder.io/optimizing-gradient-descent/</a><br>[^27]: <a href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf" target="_blank" rel="noopener">Srivastava Nitish, Geoffrey E. Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. “Dropout: a simple way to prevent neural networks from overfitting.” Journal of Machine Learning Research 15.1 (2014): 1929-1958.</a><br>[^39]: <a href="http://proceedings.mlr.press/v37/ioffe15.html" target="_blank" rel="noopener">Ioffe, Sergey, and Christian Szegedy. “Batch normalization: Accelerating deep network training by reducing internal covariate shift.” International Conference on Machine Learning. 2015.</a><br>[^44]: <a href="https://arxiv.org/pdf/1607.06450.pdf?utm_source=sciontist.com&amp;utm_medium=refer&amp;utm_campaign=promote" target="_blank" rel="noopener">Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. “Layer normalization.” arXiv preprint arXiv:1607.06450 (2016).</a><br>[^24]: <a href="http://cs231n.github.io/neural-networks-2/" target="_blank" rel="noopener">http://cs231n.github.io/neural-networks-2/</a><br>[^weightInit]: <a href="https://arxiv.org/abs/1502.01852" target="_blank" rel="noopener">https://arxiv.org/abs/1502.01852</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://yangj96.github.io/2019/03/25/linked-list/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jing Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jingy's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/25/linked-list/" class="post-title-link" itemprop="url">Leetcode链表题目总结</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-25 10:38:08" itemprop="dateCreated datePublished" datetime="2019-03-25T10:38:08+08:00">2019-03-25</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-06 23:14:56" itemprop="dateModified" datetime="2019-05-06T23:14:56+08:00">2019-05-06</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Leetcode/" itemprop="url" rel="index"><span itemprop="name">Leetcode</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">224</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Leetcode链表题常用方法总结：</p>
<ol>
<li>dummy node 常用于链表的head可能被修改或删除的情况，可简化单链表没有前向指针所带来的问题，通常使用current = dummy进行遍历，最终返回 dummy-&gt;next</li>
<li>链表中尽量避免new新的节点，而是在原链表上直接操作地址</li>
<li>在插入和删除操作中使用临时变量来存储next指针</li>
<li>通过两个指针几何变换来解决链表长度、环检测等问题</li>
<li>对于一些依赖后面节点才能完成的操作，通常使用递归来解决</li>
</ol>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Jing Yang</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                    <span class="site-state-item-count">1</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jing Yang</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">10k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">9 分钟</span>
  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v6.7.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=6.7.0"></script>

  <script src="/js/src/motion.js?v=6.7.0"></script>



  
  


  <script src="/js/src/schemes/muse.js?v=6.7.0"></script>




  

  


  <script src="/js/src/bootstrap.js?v=6.7.0"></script>



  



  

  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  

  

  

  

  

  

  

  

  

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
